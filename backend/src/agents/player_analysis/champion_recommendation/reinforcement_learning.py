"""
Champion Recommendation Reinforcement Learning Module

ä½¿ç”¨Thompson Sampling (Contextual Bandit)è¿›è¡Œè‹±é›„æ¨èçš„å¼ºåŒ–å­¦ä¹ 

æ ¸å¿ƒæ€æƒ³ï¼š
- æ¯ä¸ªè‹±é›„æœ‰ä¸€ä¸ªBetaåˆ†å¸ƒ(alpha, beta)è¡¨ç¤ºæ¨èè´¨é‡çš„ä¸ç¡®å®šæ€§
- æ¨èæ—¶ä»Betaåˆ†å¸ƒé‡‡æ ·ï¼Œå¹³è¡¡æ¢ç´¢(exploration)å’Œåˆ©ç”¨(exploitation)
- æ”¶é›†åé¦ˆåæ›´æ–°Betaåˆ†å¸ƒå‚æ•°

é€‚ç”¨åœºæ™¯ï¼š
- ç©å®¶æ¥å—æ¨èå¹¶æ¸¸ç©ï¼šæ ¹æ®èƒœè´Ÿæ›´æ–°
- ç©å®¶æ‹’ç»æ¨èï¼šè½»å¾®è´Ÿåé¦ˆ
- ç©å®¶è‡ªç„¶æ¸¸ç©æ¨èè‹±é›„ï¼šå¼ºæ­£åé¦ˆ
"""

import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class ChampionBanditState:
    """å•ä¸ªè‹±é›„çš„BanditçŠ¶æ€"""
    champion_id: int
    champion_name: str
    alpha: float  # Betaåˆ†å¸ƒå‚æ•°ï¼šæˆåŠŸæ¬¡æ•° + 1
    beta: float   # Betaåˆ†å¸ƒå‚æ•°ï¼šå¤±è´¥æ¬¡æ•° + 1
    total_recommendations: int  # æ€»æ¨èæ¬¡æ•°
    total_accepted: int  # è¢«æ¥å—æ¬¡æ•°
    total_wins: int  # æ¨èåèƒœåˆ©æ¬¡æ•°
    total_losses: int  # æ¨èåå¤±è´¥æ¬¡æ•°
    last_updated: str  # æœ€åæ›´æ–°æ—¶é—´

    @property
    def expected_value(self) -> float:
        """æœŸæœ›å€¼ï¼ˆå‡å€¼ï¼‰"""
        return self.alpha / (self.alpha + self.beta)

    @property
    def uncertainty(self) -> float:
        """ä¸ç¡®å®šæ€§ï¼ˆæ ‡å‡†å·®ï¼‰"""
        n = self.alpha + self.beta
        return np.sqrt(self.alpha * self.beta / (n * n * (n + 1)))

    @property
    def acceptance_rate(self) -> float:
        """æ¥å—ç‡"""
        if self.total_recommendations == 0:
            return 0.0
        return self.total_accepted / self.total_recommendations

    @property
    def win_rate(self) -> float:
        """æ¨èåèƒœç‡"""
        total_games = self.total_wins + self.total_losses
        if total_games == 0:
            return 0.5  # é»˜è®¤50%
        return self.total_wins / total_games


class ThompsonSamplingRecommender:
    """Thompson Sampling æ¨èç³»ç»Ÿ"""

    def __init__(
        self,
        state_file: Optional[str] = None,
        alpha_prior: float = 1.0,
        beta_prior: float = 1.0,
        exploration_bonus: float = 0.1
    ):
        """
        åˆå§‹åŒ–Thompson Samplingæ¨èå™¨

        Args:
            state_file: çŠ¶æ€æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºæŒä¹…åŒ–ï¼‰
            alpha_prior: Alphaå…ˆéªŒå€¼ï¼ˆæˆåŠŸå…ˆéªŒï¼‰
            beta_prior: Betaå…ˆéªŒå€¼ï¼ˆå¤±è´¥å…ˆéªŒï¼‰
            exploration_bonus: æ¢ç´¢å¥–åŠ±ç³»æ•°ï¼ˆé¼“åŠ±å°è¯•ä¸ç¡®å®šçš„é€‰é¡¹ï¼‰
        """
        self.state_file = Path(state_file) if state_file else None
        self.alpha_prior = alpha_prior
        self.beta_prior = beta_prior
        self.exploration_bonus = exploration_bonus

        # è‹±é›„BanditçŠ¶æ€
        self.champion_states: Dict[int, ChampionBanditState] = {}

        # åŠ è½½å·²æœ‰çŠ¶æ€
        if self.state_file and self.state_file.exists():
            self.load_state()

    def get_or_create_state(self, champion_id: int, champion_name: str) -> ChampionBanditState:
        """è·å–æˆ–åˆ›å»ºè‹±é›„çŠ¶æ€"""
        if champion_id not in self.champion_states:
            self.champion_states[champion_id] = ChampionBanditState(
                champion_id=champion_id,
                champion_name=champion_name,
                alpha=self.alpha_prior,
                beta=self.beta_prior,
                total_recommendations=0,
                total_accepted=0,
                total_wins=0,
                total_losses=0,
                last_updated=datetime.now().isoformat()
            )
        return self.champion_states[champion_id]

    def thompson_sample(self, champion_id: int, champion_name: str) -> float:
        """
        ä»Betaåˆ†å¸ƒé‡‡æ ·

        Returns:
            é‡‡æ ·å€¼ï¼ˆ0-1ä¹‹é—´ï¼Œä»£è¡¨è¯¥è‹±é›„çš„é¢„æœŸæ¨èè´¨é‡ï¼‰
        """
        state = self.get_or_create_state(champion_id, champion_name)
        sample = np.random.beta(state.alpha, state.beta)

        # æ·»åŠ æ¢ç´¢å¥–åŠ±ï¼ˆä¸ç¡®å®šæ€§è¶Šé«˜ï¼Œå¥–åŠ±è¶Šå¤§ï¼‰
        uncertainty_bonus = state.uncertainty * self.exploration_bonus

        return sample + uncertainty_bonus

    def rank_recommendations(
        self,
        candidates: List[Dict[str, Any]],
        base_scores: Optional[Dict[int, float]] = None,
        bandit_weight: float = 0.3
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨Thompson Samplingå¯¹æ¨èå€™é€‰è¿›è¡Œæ’åº

        Args:
            candidates: å€™é€‰è‹±é›„åˆ—è¡¨ï¼ˆæ¥è‡ªé™æ€æ¨èç³»ç»Ÿï¼‰
            base_scores: åŸºç¡€è¯„åˆ†å­—å…¸ {champion_id: score}
            bandit_weight: Banditè¯„åˆ†æƒé‡ï¼ˆ0-1ï¼‰ï¼Œå‰©ä½™æƒé‡ç»™base_scores

        Returns:
            é‡æ–°æ’åºåçš„æ¨èåˆ—è¡¨
        """
        if not candidates:
            return []

        # ä¸ºæ¯ä¸ªå€™é€‰è®¡ç®—ç»¼åˆè¯„åˆ†
        scored_candidates = []
        for cand in candidates:
            champ_id = cand["champion_id"]
            champ_name = cand.get("champion_name", f"Champion_{champ_id}")

            # Thompson Samplingé‡‡æ ·å€¼
            ts_score = self.thompson_sample(champ_id, champ_name)

            # åŸºç¡€è¯„åˆ†ï¼ˆå¦‚æœæä¾›ï¼‰
            base_score = base_scores.get(champ_id, 0.5) if base_scores else 0.5

            # ç»¼åˆè¯„åˆ†
            final_score = bandit_weight * ts_score + (1 - bandit_weight) * base_score

            # æ·»åŠ åˆ°å€™é€‰
            scored_candidates.append({
                **cand,
                "ts_sample": round(ts_score, 4),
                "base_score": round(base_score, 4),
                "rl_final_score": round(final_score, 4),
                "bandit_state": {
                    "alpha": self.champion_states[champ_id].alpha if champ_id in self.champion_states else self.alpha_prior,
                    "beta": self.champion_states[champ_id].beta if champ_id in self.champion_states else self.beta_prior,
                    "expected_value": self.champion_states[champ_id].expected_value if champ_id in self.champion_states else 0.5,
                    "uncertainty": self.champion_states[champ_id].uncertainty if champ_id in self.champion_states else 0.5
                }
            })

        # æŒ‰rl_final_scoreé™åºæ’åº
        scored_candidates.sort(key=lambda x: x["rl_final_score"], reverse=True)

        return scored_candidates

    def update_feedback(
        self,
        champion_id: int,
        champion_name: str,
        feedback_type: str,
        outcome: Optional[str] = None
    ):
        """
        æ›´æ–°è‹±é›„åé¦ˆ

        Args:
            champion_id: è‹±é›„ID
            champion_name: è‹±é›„åç§°
            feedback_type: åé¦ˆç±»å‹
                - "recommended": æ¨èç»™ç”¨æˆ·
                - "accepted": ç”¨æˆ·æ¥å—æ¨è
                - "rejected": ç”¨æˆ·æ‹’ç»æ¨è
            outcome: æ¸¸æˆç»“æœï¼ˆä»…å½“feedback_type="accepted"æ—¶ï¼‰
                - "win": èƒœåˆ©
                - "loss": å¤±è´¥
                - None: å°šæœªå®Œæˆæ¸¸æˆ
        """
        state = self.get_or_create_state(champion_id, champion_name)

        if feedback_type == "recommended":
            state.total_recommendations += 1

        elif feedback_type == "accepted":
            state.total_accepted += 1

            if outcome == "win":
                state.total_wins += 1
                state.alpha += 1.0  # å¼ºæ­£åé¦ˆ
                print(f"  âœ… {champion_name} æ¨èè¢«æ¥å—å¹¶èƒœåˆ©ï¼Œalpha += 1.0")

            elif outcome == "loss":
                state.total_losses += 1
                state.beta += 0.5  # å¼±è´Ÿåé¦ˆï¼ˆå¤±è´¥ä¹Ÿæ˜¯å­¦ä¹ ï¼‰
                print(f"  âŒ {champion_name} æ¨èè¢«æ¥å—ä½†å¤±è´¥ï¼Œbeta += 0.5")

            else:
                # æ¥å—ä½†å°šæœªå®Œæˆæ¸¸æˆ
                state.alpha += 0.3  # è½»å¾®æ­£åé¦ˆï¼ˆæ¥å—æœ¬èº«æ˜¯ä¿¡å·ï¼‰
                print(f"  ğŸ¯ {champion_name} æ¨èè¢«æ¥å—ï¼Œalpha += 0.3")

        elif feedback_type == "rejected":
            state.beta += 0.2  # è½»å¾®è´Ÿåé¦ˆ
            print(f"  â­ï¸  {champion_name} æ¨èè¢«æ‹’ç»ï¼Œbeta += 0.2")

        state.last_updated = datetime.now().isoformat()

        # ä¿å­˜çŠ¶æ€
        if self.state_file:
            self.save_state()

    def batch_update_from_history(
        self,
        recommendation_history: List[Dict[str, Any]]
    ):
        """
        ä»å†å²æ¨èè®°å½•æ‰¹é‡æ›´æ–°

        Args:
            recommendation_history: æ¨èå†å²åˆ—è¡¨
                [
                    {
                        "champion_id": 92,
                        "champion_name": "Riven",
                        "recommended_at": "2025-10-11T10:00:00",
                        "accepted": true,
                        "outcome": "win"
                    },
                    ...
                ]
        """
        print(f"\nğŸ”„ ä»å†å²è®°å½•æ‰¹é‡æ›´æ–° ({len(recommendation_history)}æ¡)")

        for record in recommendation_history:
            champ_id = record["champion_id"]
            champ_name = record.get("champion_name", f"Champion_{champ_id}")

            # æ ‡è®°ä¸ºæ¨è
            self.update_feedback(champ_id, champ_name, "recommended")

            # å¤„ç†æ¥å—/æ‹’ç»
            if record.get("accepted", False):
                outcome = record.get("outcome", None)
                self.update_feedback(champ_id, champ_name, "accepted", outcome)
            else:
                self.update_feedback(champ_id, champ_name, "rejected")

        print(f"âœ… æ‰¹é‡æ›´æ–°å®Œæˆ")

    def get_state_summary(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€æ‘˜è¦"""
        if not self.champion_states:
            return {
                "total_champions": 0,
                "total_recommendations": 0,
                "total_accepted": 0,
                "global_acceptance_rate": 0.0
            }

        total_recs = sum(s.total_recommendations for s in self.champion_states.values())
        total_accepted = sum(s.total_accepted for s in self.champion_states.values())

        return {
            "total_champions": len(self.champion_states),
            "total_recommendations": total_recs,
            "total_accepted": total_accepted,
            "global_acceptance_rate": total_accepted / total_recs if total_recs > 0 else 0.0,
            "top_champions": [
                {
                    "champion_id": state.champion_id,
                    "champion_name": state.champion_name,
                    "expected_value": round(state.expected_value, 3),
                    "uncertainty": round(state.uncertainty, 3),
                    "total_recommendations": state.total_recommendations,
                    "acceptance_rate": round(state.acceptance_rate, 3),
                    "win_rate": round(state.win_rate, 3)
                }
                for state in sorted(
                    self.champion_states.values(),
                    key=lambda s: s.expected_value,
                    reverse=True
                )[:10]
            ]
        }

    def save_state(self):
        """ä¿å­˜çŠ¶æ€åˆ°æ–‡ä»¶"""
        if not self.state_file:
            return

        self.state_file.parent.mkdir(parents=True, exist_ok=True)

        state_data = {
            "config": {
                "alpha_prior": self.alpha_prior,
                "beta_prior": self.beta_prior,
                "exploration_bonus": self.exploration_bonus
            },
            "champion_states": {
                str(champ_id): asdict(state)
                for champ_id, state in self.champion_states.items()
            },
            "summary": self.get_state_summary(),
            "last_saved": datetime.now().isoformat()
        }

        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(state_data, f, indent=2, ensure_ascii=False)

    def load_state(self):
        """ä»æ–‡ä»¶åŠ è½½çŠ¶æ€"""
        if not self.state_file or not self.state_file.exists():
            return

        with open(self.state_file, 'r', encoding='utf-8') as f:
            state_data = json.load(f)

        # åŠ è½½é…ç½®
        config = state_data.get("config", {})
        self.alpha_prior = config.get("alpha_prior", self.alpha_prior)
        self.beta_prior = config.get("beta_prior", self.beta_prior)
        self.exploration_bonus = config.get("exploration_bonus", self.exploration_bonus)

        # åŠ è½½è‹±é›„çŠ¶æ€
        champion_states_data = state_data.get("champion_states", {})
        for champ_id_str, state_dict in champion_states_data.items():
            champ_id = int(champ_id_str)
            self.champion_states[champ_id] = ChampionBanditState(**state_dict)

        print(f"âœ… åŠ è½½RLçŠ¶æ€: {len(self.champion_states)}ä¸ªè‹±é›„, "
              f"{state_data['summary']['total_recommendations']}æ¬¡æ¨è")


def create_default_recommender(project_root: Optional[Path] = None) -> ThompsonSamplingRecommender:
    """
    åˆ›å»ºé»˜è®¤çš„Thompson Samplingæ¨èå™¨

    Args:
        project_root: é¡¹ç›®æ ¹ç›®å½•ï¼ˆç”¨äºå®šä½stateæ–‡ä»¶ï¼‰

    Returns:
        ThompsonSamplingRecommenderå®ä¾‹
    """
    if project_root is None:
        project_root = Path(__file__).parent.parent.parent.parent.parent

    state_file = project_root / "data/baselines/champion_recommendation_rl_state.json"

    return ThompsonSamplingRecommender(
        state_file=str(state_file),
        alpha_prior=1.0,  # ä¸­æ€§å…ˆéªŒï¼ˆå¯¹æ‰€æœ‰è‹±é›„ä¸€è§†åŒä»ï¼‰
        beta_prior=1.0,
        exploration_bonus=0.1  # 10%æ¢ç´¢å¥–åŠ±
    )
