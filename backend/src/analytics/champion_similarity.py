#!/usr/bin/env python3
"""
Champion Similarity Calculator
è‹±é›„ç›¸ä¼¼åº¦è®¡ç®—æ¨¡å—

åŸºäºå¤šç»´ç»Ÿè®¡ç‰¹å¾è®¡ç®—è‹±é›„ä¹‹é—´çš„ç›¸ä¼¼åº¦çŸ©é˜µ
"""

import duckdb
import numpy as np
import json
from pathlib import Path
from typing import Dict, Any, List, Tuple
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ChampionSimilarityCalculator:
    """è‹±é›„ç›¸ä¼¼åº¦è®¡ç®—å™¨"""

    # ç”¨äºè®¡ç®—ç›¸ä¼¼åº¦çš„ç‰¹å¾ç»´åº¦
    FEATURE_COLUMNS = [
        'avg_kills', 'avg_deaths', 'avg_assists',
        'avg_kda_ratio',
        'avg_cs_per_minute',
        'avg_gold_per_minute',
        'avg_damage_per_minute',
        'avg_damage_taken',
        'avg_vision_score_per_minute',
        'avg_turret_kills',
        'avg_dragon_kills',
        'avg_baron_kills',
    ]

    def __init__(
        self,
        parquet_path: str,
        min_games: int = 50
    ):
        """
        åˆå§‹åŒ–è‹±é›„ç›¸ä¼¼åº¦è®¡ç®—å™¨

        Args:
            parquet_path: Gold layer Parquetæ–‡ä»¶è·¯å¾„
            min_games: è®¡ç®—ç›¸ä¼¼åº¦æ‰€éœ€çš„æœ€å°æ¸¸æˆåœºæ¬¡
        """
        self.parquet_path = Path(parquet_path)
        self.min_games = min_games

        if not self.parquet_path.exists():
            raise FileNotFoundError(f"Parquetæ–‡ä»¶ä¸å­˜åœ¨: {parquet_path}")

    def _extract_champion_features(self) -> Tuple[Dict[int, str], np.ndarray]:
        """
        ä»Parquetæ–‡ä»¶æå–è‹±é›„ç‰¹å¾å‘é‡

        Returns:
            (champion_id_to_nameæ˜ å°„, ç‰¹å¾çŸ©é˜µ)
        """
        logger.info(f"ğŸ“Š æ­£åœ¨ä» {self.parquet_path} æå–è‹±é›„ç‰¹å¾...")

        conn = duckdb.connect(":memory:")

        # èšåˆæ¯ä¸ªè‹±é›„çš„ç»Ÿè®¡æ•°æ®
        feature_list = ', '.join([f'AVG({col.replace("avg_", "")}) as {col}'
                                   for col in self.FEATURE_COLUMNS])

        query = f"""
        SELECT
            champion_id,
            champion_name,
            COUNT(*) as total_games,
            {feature_list}
        FROM read_parquet(?)
        WHERE champion_id IS NOT NULL
        GROUP BY champion_id, champion_name
        HAVING COUNT(*) >= ?
        ORDER BY champion_id
        """

        result = conn.execute(query, [str(self.parquet_path), self.min_games]).fetchall()
        conn.close()

        if not result:
            raise ValueError(f"æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³æœ€å°æ¸¸æˆåœºæ¬¡({self.min_games})çš„è‹±é›„æ•°æ®")

        # æ„å»ºchampion_idæ˜ å°„å’Œç‰¹å¾çŸ©é˜µ
        champion_mapping = {}
        features = []

        for row in result:
            champion_id = row[0]
            champion_name = row[1]
            # total_games = row[2]
            feature_vector = row[3:]  # ä»ç¬¬4åˆ—å¼€å§‹æ˜¯ç‰¹å¾

            champion_mapping[champion_id] = champion_name
            features.append(feature_vector)

        features_array = np.array(features, dtype=float)

        logger.info(f"âœ… æå–äº† {len(champion_mapping)} ä¸ªè‹±é›„çš„ç‰¹å¾å‘é‡")

        return champion_mapping, features_array

    def calculate_similarity_matrix(self) -> Dict[str, Any]:
        """
        è®¡ç®—è‹±é›„ç›¸ä¼¼åº¦çŸ©é˜µ

        Returns:
            ç›¸ä¼¼åº¦çŸ©é˜µæ•°æ®ï¼Œæ ¼å¼ï¼š
            {
                "champions": {champion_id: champion_name},
                "similarity_matrix": [[sim_00, sim_01, ...], ...],
                "top_similar": {champion_id: [(similar_id, score), ...]}
            }
        """
        # æå–ç‰¹å¾
        champion_mapping, features = self._extract_champion_features()

        # æ ‡å‡†åŒ–ç‰¹å¾ï¼ˆZ-score normalizationï¼‰
        logger.info("ğŸ”„ æ­£åœ¨æ ‡å‡†åŒ–ç‰¹å¾å‘é‡...")
        scaler = StandardScaler()
        features_normalized = scaler.fit_transform(features)

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ
        logger.info("ğŸ”„ æ­£åœ¨è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ...")
        similarity_matrix = cosine_similarity(features_normalized)

        # å°†å¯¹è§’çº¿è®¾ä¸º0ï¼ˆè‹±é›„ä¸è‡ªå·±çš„ç›¸ä¼¼åº¦ä¸è€ƒè™‘ï¼‰
        np.fill_diagonal(similarity_matrix, 0)

        logger.info(f"âœ… æˆåŠŸè®¡ç®— {len(champion_mapping)}Ã—{len(champion_mapping)} ç›¸ä¼¼åº¦çŸ©é˜µ")

        return {
            "champions": champion_mapping,
            "similarity_matrix": similarity_matrix.tolist(),
            "feature_columns": self.FEATURE_COLUMNS
        }

    def get_top_similar(
        self,
        similarity_data: Dict[str, Any],
        top_k: int = 5
    ) -> Dict[int, List[Tuple[int, float]]]:
        """
        è·å–æ¯ä¸ªè‹±é›„æœ€ç›¸ä¼¼çš„Top-Kè‹±é›„

        Args:
            similarity_data: calculate_similarity_matrixè¿”å›çš„æ•°æ®
            top_k: è¿”å›å‰Kä¸ªæœ€ç›¸ä¼¼çš„è‹±é›„

        Returns:
            {champion_id: [(similar_champion_id, similarity_score), ...]}
        """
        logger.info(f"ğŸ”„ æ­£åœ¨è®¡ç®—æ¯ä¸ªè‹±é›„çš„Top-{top_k}ç›¸ä¼¼è‹±é›„...")

        champions = similarity_data["champions"]
        similarity_matrix = np.array(similarity_data["similarity_matrix"])

        champion_ids = list(champions.keys())
        top_similar = {}

        for i, champion_id in enumerate(champion_ids):
            # è·å–å½“å‰è‹±é›„ä¸å…¶ä»–æ‰€æœ‰è‹±é›„çš„ç›¸ä¼¼åº¦
            similarities = similarity_matrix[i]

            # è·å–Top-Kæœ€é«˜çš„ç›¸ä¼¼åº¦ç´¢å¼•
            top_indices = np.argsort(similarities)[::-1][:top_k]

            # æ„å»º(ç›¸ä¼¼è‹±é›„ID, ç›¸ä¼¼åº¦åˆ†æ•°)åˆ—è¡¨
            top_similar[champion_id] = [
                (champion_ids[idx], round(float(similarities[idx]), 4))
                for idx in top_indices
            ]

        logger.info(f"âœ… æˆåŠŸè®¡ç®—æ‰€æœ‰è‹±é›„çš„Top-{top_k}ç›¸ä¼¼è‹±é›„")

        return top_similar

    def save(self, output_path: str, top_k: int = 10) -> None:
        """
        è®¡ç®—å¹¶ä¿å­˜è‹±é›„ç›¸ä¼¼åº¦æ•°æ®åˆ°JSONæ–‡ä»¶

        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            top_k: ä¿å­˜æ¯ä¸ªè‹±é›„çš„Top-Kç›¸ä¼¼è‹±é›„
        """
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        similarity_data = self.calculate_similarity_matrix()

        # è®¡ç®—Top-Kç›¸ä¼¼è‹±é›„
        top_similar = self.get_top_similar(similarity_data, top_k=top_k)

        # å‡†å¤‡è¾“å‡ºæ•°æ®ï¼ˆä¸åŒ…å«å®Œæ•´çŸ©é˜µï¼Œåªä¿å­˜Top-Kï¼‰
        output_data = {
            "champions": similarity_data["champions"],
            "feature_columns": similarity_data["feature_columns"],
            "top_similar": {
                str(champ_id): [
                    {
                        "champion_id": sim_id,
                        "champion_name": similarity_data["champions"][sim_id],
                        "similarity_score": score
                    }
                    for sim_id, score in similar_list
                ]
                for champ_id, similar_list in top_similar.items()
            },
            "metadata": {
                "min_games": self.min_games,
                "total_champions": len(similarity_data["champions"]),
                "top_k": top_k
            }
        }

        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ’¾ è‹±é›„ç›¸ä¼¼åº¦æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")

        # æ‰“å°æ‘˜è¦
        self._print_summary(output_data, top_k=5)

    def _print_summary(self, data: Dict[str, Any], top_k: int = 5) -> None:
        """æ‰“å°ç›¸ä¼¼åº¦è®¡ç®—æ‘˜è¦"""
        print("\n" + "="*80)
        print("è‹±é›„ç›¸ä¼¼åº¦è®¡ç®—æ‘˜è¦")
        print("="*80)
        print(f"æ€»è‹±é›„æ•°: {data['metadata']['total_champions']}")
        print(f"æœ€å°æ¸¸æˆåœºæ¬¡: {data['metadata']['min_games']}")
        print(f"ç‰¹å¾ç»´åº¦: {len(data['feature_columns'])}")
        print("\nç¤ºä¾‹ - å‰3ä¸ªè‹±é›„çš„Top-{} ç›¸ä¼¼è‹±é›„:".format(top_k))
        print("-"*80)

        for i, (champ_id, similar_list) in enumerate(list(data['top_similar'].items())[:3]):
            champ_name = data['champions'][int(champ_id)]
            print(f"\n{champ_name} (ID: {champ_id}):")
            for rank, similar in enumerate(similar_list[:top_k], 1):
                print(f"  {rank}. {similar['champion_name']:<20} (ç›¸ä¼¼åº¦: {similar['similarity_score']:.3f})")

        print("\n" + "="*80 + "\n")
